LLM_PROVIDER=openai

# OpenAI
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
OPENAI_MODEL_FAST=gpt-4o-mini-high
# Specific override for KnowledgeAgent (optional). Falls back to OPENAI_MODEL_FAST or OPENAI_MODEL
OPENAI_MODEL_KNOWLEDGE=
OPENAI_EMBED_MODEL=text-embedding-3-small
# Optional faster embedding model (if available in your account)
OPENAI_EMBED_MODEL_FAST=
# Optional token caps for KnowledgeAgent
OPENAI_MAX_TOKENS_KNOWLEDGE=
OPENAI_MAX_TOKENS_KNOWLEDGE_RETRY=

# Embeddings (fallback if not using OpenAI)
EMBEDDINGS_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Web search (optional)
TAVILY_API_KEY=
FIRECRAWL_API_KEY=

# LangSmith / LangChain tracing (optional)
LANGSMITH_API_KEY=
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=PS-CloudWalk

# Vector backend (Milvus only)
VECTOR_BACKEND=milvus

# Zilliz Cloud Configuration (Milvus Managed)
ZILLIZ_CLOUD_URI=https://in03-30feefc799b6017.serverless.gcp-us-west1.cloud.zilliz.com
ZILLIZ_CLOUD_TOKEN=679dd085b14284c30e4df9a70ce6010a5850ab131c204dd666e6f0a004e03d01a829fd486262ad9ec9004b360de8f9aae99eb82c
ZILLIZ_CLOUD_COLLECTION_CHUNKS=ps_chunks
ZILLIZ_CLOUD_COLLECTION_FAQ=ps_faq
ZILLIZ_CLOUD_DIM=1536
ZILLIZ_CLOUD_METRIC=COSINE

# (Removed) Neo4j settings ‚Äì graph disabled

# App
APP_ENV=dev
LOG_LEVEL=INFO

# Supabase / Postgres (LangGraph checkpointer)
DATABASE_URL=

# Rate limiting
RATE_LIMIT_PER_MINUTE=60

# Slack (CustomAgent)
SLACK_BOT_TOKEN=
SLACK_DEFAULT_CHANNEL=#support

# Retrieval knobs
RAG_VECTOR_K=3
RAG_VECTOR_K_FEES=2
RAG_GRAPH_WEIGHT=0.0
RAG_VECTOR_WEIGHT=0.4
RAG_MAX_CONTEXT_CHARS=3000

# Zilliz Cloud performance tuning
ZILLIZ_EF_SEARCH=64
RAG_FETCH_K=2
RAG_MMR_LAMBDA=0.5
RAG_SOURCES_MAX=2
RAG_FULLTEXT_MIN_SCORE=0.0

# Index-time chunking (applies during ingestion)
RAG_INDEX_CHUNK_CHARS=900
RAG_INDEX_CHUNK_OVERLAP=120

# üöÄ Performance Optimizations
RAG_EMBED_CACHE=true
RAG_VECTOR_CACHE_TTL=60
RAG_WARMUP_ON_START=true
MIN_ANSWER_LENGTH=40
KNOWLEDGE_CACHE_TTL=300

# üóÑÔ∏è Cache Manager Configuration
EMBEDDING_CACHE_SIZE=1000
LLM_CACHE_SIZE=500
RETRIEVER_CACHE_SIZE=10
GENERAL_CACHE_SIZE=100
EMBEDDING_CACHE_TTL=3600
LLM_CACHE_TTL=300
RETRIEVER_CACHE_TTL=600
GENERAL_CACHE_TTL=300

# ‚ö° Retrieval Orchestrator Configuration
RETRIEVAL_MAX_WORKERS=4
ENABLE_PARALLEL_RETRIEVAL=true
QUERY_COMPLEXITY_THRESHOLD=10

# üìù Context Builder Configuration
RAG_MAX_CONTEXT_CHARS=3000
RAG_MIN_CHARS_FAQ=600
RAG_MIN_CHARS_DOCS=800
RAG_MIN_CHARS_GRAPH=600

# üîç LangSmith Profiling Configuration
ENABLE_PROFILING=true
PROFILING_DETAIL_LEVEL=medium  # low, medium, high

# üéØ Agent-Specific Optimizations
RAG_VECTOR_K=3
RAG_VECTOR_K_FEES=2
RAG_GRAPH_WEIGHT=0.6
RAG_VECTOR_WEIGHT=0.4
HANDOFF_THRESHOLD=0.45

# (Removed) Graph knobs ‚Äì graph disabled

# Feature toggles
ENABLE_GRAPH=false
ENABLE_VECTOR=true
ENABLE_FAQ=true

